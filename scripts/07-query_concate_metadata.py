# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/00_ngame-for-msmarco-inference.ipynb.

# %% auto 0
__all__ = []

# %% ../nbs/00_ngame-for-msmarco-inference.ipynb 3
import os, torch,json, torch.multiprocessing as mp, joblib, numpy as np, scipy.sparse as sp, argparse
from tqdm.auto import tqdm

from xcai.basics import *
from sugar.core import *

from xclib.utils.sparse import retain_topk

DATASETS = [
    "arguana",
    "msmarco",
    "climate-fever",
    "dbpedia-entity",
    "fever",
    "fiqa",
    "hotpotqa",
    "nfcorpus",
    "nq",
    "quora",
    "scidocs",
    "scifact",
    "webis-touche2020",
    "trec-covid",
    "cqadupstack/android",
    "cqadupstack/english",
    "cqadupstack/gaming",
    "cqadupstack/gis",
    "cqadupstack/mathematica",
    "cqadupstack/physics",
    "cqadupstack/programmers",
    "cqadupstack/stats",
    "cqadupstack/tex",
    "cqadupstack/unix",
    "cqadupstack/webmasters",
    "cqadupstack/wordpress"
]

# %% ../nbs/00_ngame-for-msmarco-inference.ipynb 20
if __name__ == '__main__':
    output_dir = "/data/outputs/upma/00_msmarco-gpt-concept-substring-linker-with-ngame-loss-001/"

    # Metadata information
    info_file = "/data/datasets/beir/msmarco/XC/concept_substrings/raw_data/concept-substring.raw.csv"
    meta_info = Info.from_txt(info_file, info_column_names=["identifier", "input_text"])

    os.makedirs(f"{output_dir}/raw_data", exist_ok=True)

    def get_input_text(dataset, dset_type:str):
        # basic dataset
        info_file = f"/data/datasets/beir/{dataset}/XC/raw_data/{dset_type}.raw.csv"
        data_info = Info.from_txt(info_file, info_column_names=["identifier", "input_text"])

        # Metadata predictions
        dataset = dataset.replace("/", "-")
        meta_file = f"{output_dir}/predictions/{dset_type}_predictions"
        meta_file = f"{meta_file}.npz" if dataset == "msmarco" else f"{meta_file}_{dataset}.npz"
        data_meta = retain_topk(sp.load_npz(meta_file), k=5)
        data_text = [txt+" [SEP] "+" [SEP] ".join(meta_info["input_text"][i] for i in row.indices) for txt,row in zip(data_info["input_text"],data_meta)]

        info_file = f"{output_dir}/raw_data/{dset_type}_{dataset}.raw.csv"
        save_raw_file(info_file, data_info["identifier"], data_text) 

    for dataset in tqdm(DATASETS):
        get_input_text(dataset, "test")

        if dataset == "msmarco": 
            get_input_text(dataset, "train")

