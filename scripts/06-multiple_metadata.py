# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/00_ngame-for-msmarco-inference.ipynb.

# %% auto 0
__all__ = []

# %% ../nbs/00_ngame-for-msmarco-inference.ipynb 3
import os, torch,json, torch.multiprocessing as mp, joblib, numpy as np, scipy.sparse as sp, argparse
from tqdm.auto import tqdm

from xcai.basics import *
from xcai.analysis import *

DATASETS = [
    "msmarco",
    "arguana",
    "climate-fever",
    "dbpedia-entity",
    "fever",
    "fiqa",
    "hotpotqa",
    "nfcorpus",
    "nq",
    "quora",
    "scidocs",
    "scifact",
    "webis-touche2020",
    "trec-covid",
    "cqadupstack/android",
    "cqadupstack/english",
    "cqadupstack/gaming",
    "cqadupstack/gis",
    "cqadupstack/mathematica",
    "cqadupstack/physics",
    "cqadupstack/programmers",
    "cqadupstack/stats",
    "cqadupstack/tex",
    "cqadupstack/unix",
    "cqadupstack/webmasters",
    "cqadupstack/wordpress"
]

def additional_args():
    parser = argparse.ArgumentParser()
    parser.add_argument('--num_examples', type=int, default=20)
    return parser.parse_known_args()[0]

# %% ../nbs/00_ngame-for-msmarco-inference.ipynb 20
if __name__ == '__main__':
    output_dir = "/home/aiscuser/scratch1/examples/"

    pickle_dir = "/home/aiscuser/scratch1/datasets/processed/"
    mname = "distilbert-base-uncased"

    extra_args = additional_args()

    # Metadata information
    info_file = "/data/datasets/beir/msmarco/XC/concept_substrings/raw_data/concept-substring.raw.csv"
    sub_info = Info.from_txt(info_file, info_column_names=["identifier", "input_text"])
    sub_dir = "/data/outputs/upma/00_msmarco-gpt-concept-substring-linker-with-ngame-loss-001/predictions/"

    sub_output_dir = "/data/outputs/upma/03_upma-with-ngame-gpt-substring-linker-for-msmarco-002/predictions/"

    info_file = "/data/datasets/beir/msmarco/XC/raw_data/category-gpt-linker_conflated-001_conflated-001.raw.csv"
    cat_info = Info.from_txt(info_file, info_column_names=["identifier", "input_text"])
    cat_dir = "/data/outputs/mogicX/47_msmarco-gpt-category-linker-002/predictions/"

    cat_output_dir = "/data/outputs/mogicX/50_distilbert-ngame-category-linker-oracle-for-msmarco-002/predictions/47_msmarco-gpt-category-linker-002/"

    for dataset in tqdm(DATASETS):
        # basic dataset
        config_file = f"/data/datasets/beir/{dataset}/XC/configs/data.json"
        config_key, fname = get_config_key(config_file)

        dataset = dataset.replace("/", "-")
        pkl_file = get_pkl_file(pickle_dir, f"{dataset}_{fname}_distilbert-base-uncased", use_sxc_sampler=True, use_only_test=True)
        block = build_block(pkl_file, config_file, use_sxc=True, config_key=config_key, only_test=True, main_oversample=True,
                            return_scores=True, n_slbl_samples=1)

        # Metadata predictions
        data_sub = sp.load_npz(f"{sub_dir}/test_predictions_{dataset}.npz")
        data_cat = sp.load_npz(f"{cat_dir}/test_predictions_{dataset}.npz")

        # Label predictions
        data_lbl_sub = sp.load_npz(f"{sub_output_dir}/test_predictions_{dataset}.npz")
        data_lbl_cat = sp.load_npz(f"{cat_output_dir}/test_predictions_{dataset}.npz")

        assert data_sub.shape == data_cat.shape
        assert data_lbl_sub.shape == data_lbl_cat.shape

        # Prediction scores
        sub_scores = pointwise_eval(data_lbl_sub, block.test.dset.data.data_lbl, topk=5, metric="P")
        sub_scores = np.array(sub_scores.sum(axis=1)).flatten()
        cat_scores = pointwise_eval(data_lbl_cat, block.test.dset.data.data_lbl, topk=5, metric="P")
        cat_scores = np.array(cat_scores.sum(axis=1)).flatten()

        # Dataset
        meta_kwargs = {
            "sub_meta": SMetaXCDataset(prefix="sub", data_meta=data_sub, meta_info=sub_info, return_scores=True),
            "cat_meta": SMetaXCDataset(prefix="cat", data_meta=data_cat, meta_info=cat_info, return_scores=True),
        }
        test_dset = SXCDataset(block.test.dset.data, **meta_kwargs)

        # Display predictions
        example_dir = f"{output_dir}/examples"
        os.makedirs(example_dir, exist_ok=True)
        disp_block = TextDataset(test_dset, pattern=".*(_text|_scores)$", combine_info=True, sort_by="scores")

        np.random.seed(1000)
        idxs = np.random.permutation(data_sub.shape[0])[:extra_args.num_examples]

        items = [disp_block.combine_by_prefix(disp_block[idx]) if disp_block.combine_info else disp_block[idx] for idx in idxs]
        for idx, item in zip(idxs, items): item.update({"data_substring_metric":sub_scores[idx], "data_category_metric":cat_scores[idx]})

        with open(f"{example_dir}/test_examples_{dataset}.json", 'w') as file:
            json.dump(items, file, indent=4)

