# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/37_training-msmarco-distilbert-from-scratch.ipynb.

# %% auto 0
__all__ = []

# %% ../nbs/37_training-msmarco-distilbert-from-scratch.ipynb 2
import os
# os.environ["CUDA_VISIBLE_DEVICES"] = "2,3"

import torch,json, torch.multiprocessing as mp, joblib, numpy as np, scipy.sparse as sp, argparse

from xcai.misc import *
from xcai.basics import *

# %% ../nbs/37_training-msmarco-distilbert-from-scratch.ipynb 4
os.environ["WANDB_PROJECT"] = "02_upma-msmarco-gpt-concept-substring"

# %% ../nbs/37_training-msmarco-distilbert-from-scratch.ipynb 21
if __name__ == '__main__':
    input_args = parse_args()

    output_dir = "/home/aiscuser/scratch1/outputs/upma/03_upma-with-ngame-gpt-substring-linker-for-msmarco-007"

    input_args.use_sxc_sampler = True
    input_args.pickle_dir = "/home/aiscuser/scratch1/datasets/processed/"
    mname = "distilbert-base-uncased"

    if input_args.beir_mode:
        meta_file = "/data/datasets/beir/msmarco/XC/substring/conflation_02/raw_data/substring.raw.csv"
        linker_dir = "/data/outputs/upma/00_msmarco-gpt-concept-substring-linker-with-ngame-loss-003/"
        upma_beir_inference(output_dir, input_args, mname, "msmarco-substring-conflation-02", meta_file, linker_dir, eval_batch_size=200, 
                            data_repr_pooling=False)
    else:
        config_file = (
            "configs/msmarco/substring/data_lbl_ngame-gpt-substring-conflation-02_ce-negatives-topk-05-linker_exact.json"
            if input_args.exact else
            "configs/msmarco/substring/data_lbl_ngame-gpt-substring-conflation-02.json"
        )
        train_dset, test_dset = load_upma_block("msmarco", config_file, input_args)
        upma_run(output_dir, input_args, mname, test_dset, train_dset, train_batch_size=128, data_repr_pooling=False)

