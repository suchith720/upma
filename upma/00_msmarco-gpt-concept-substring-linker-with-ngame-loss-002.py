# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/00_ngame-for-msmarco-inference.ipynb.

# %% auto 0
__all__ = []

# %% ../nbs/00_ngame-for-msmarco-inference.ipynb 3
import os
# os.environ['CUDA_VISIBLE_DEVICES'] = "2,3"

import torch,json, torch.multiprocessing as mp, joblib, numpy as np, scipy.sparse as sp, argparse
from typing import Optional, Union, Callable
from tqdm.auto import tqdm

from xcai.basics import *
from xcai.misc import *
from xcai.models.PPP0XX import DBT009, DBTConfig

# %% ../nbs/00_ngame-for-msmarco-inference.ipynb 5
os.environ['WANDB_PROJECT'] = "01_upma-msmarco-gpt-concept-substring-linker"

# %% ../nbs/00_ngame-for-msmarco-inference.ipynb 20
if __name__ == '__main__':
    output_dir = "/data/outputs/upma/00_msmarco-gpt-concept-substring-linker-with-ngame-loss-002"

    input_args = parse_args()
    extra_args = additional_args()

    input_args.use_sxc_sampler = True
    input_args.pickle_dir = "/home/aiscuser/scratch1/datasets/processed/"
    mname = "sentence-transformers/msmarco-distilbert-cos-v5"

    if input_args.beir_mode:
        meta_dir, save_file_name, pred_dir_name = "substring/conflation_01/raw_data/", "msmarco-substring-conflation-01", "predictions"
        meta_file = f"{meta_dir}/substring.raw.csv"
        linker_beir_inference(output_dir, input_args, mname, save_file_name=save_file_name, meta_file=meta_file)
    else:
        config_file = "/data/datasets/beir/msmarco/XC/configs/data_gpt-substring-conflation-01.json"

        train_dset, test_dset = load_linker_block("msmarco", config_file, input_args, extra_args)
        linker_run(output_dir, input_args, mname, test_dset, train_dset)

    
    
